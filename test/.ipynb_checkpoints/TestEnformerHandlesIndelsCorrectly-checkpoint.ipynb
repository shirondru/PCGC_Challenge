{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee58e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from joblib import Parallel,delayed\n",
    "import tensorflow_hub as hub\n",
    "import joblib\n",
    "import gzip\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import biomart\n",
    "from scipy.stats import zscore\n",
    "from pandas import HDFStore\n",
    "import h5py\n",
    "import itertools\n",
    "import argparse\n",
    "import sys\n",
    "import datetime\n",
    "model_path = \"/wynton/home/hernandez/shirondru/pollard_lab/enformer\"\n",
    "fasta_file = '/wynton/home/hernandez/shirondru/pollard_lab/data/hg38_genome.fa'\n",
    "clinvar_vcf = '/wynton/home/hernandez/shirondru/pollard_lab/data/clinvar.vcf.gz'\n",
    "\n",
    "\n",
    "# cols = ['chrom','txStart','txEnd','ENST','strand',,'cdsStart','cdsEnd','exonCount','exonStarts','exonEnds','ENST_y','A','B','C','D','Gene','E','F']\n",
    "gene_annotations = pd.read_csv(\"/wynton/home/hernandez/shirondru/pollard_lab/data/knownGene.tsv\",sep = '\\t') #from ucsc genome browser hg38\n",
    "\n",
    "\n",
    "# Download targets from Basenji2 dataset \n",
    "# Cite: Kelley et al Cross-species regulatory sequence activity prediction. PLoS Comput. Biol. 16, e1008050 (2020).\n",
    "df_targets = pd.read_csv(\"/wynton/home/hernandez/shirondru/pollard_lab/data/enformer_df_targets.csv\")\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "# @title `Enformer`, `EnformerScoreVariantsNormalized`, `EnformerScoreVariantsPCANormalized`,\n",
    "SEQUENCE_LENGTH = 393216\n",
    "\n",
    "class Enformer:\n",
    "\n",
    "  def __init__(self, tfhub_url):\n",
    "    self._model = hub.load(tfhub_url).model\n",
    "\n",
    "  def predict_on_batch(self, inputs):\n",
    "    predictions = self._model.predict_on_batch(inputs)\n",
    "    return {k: v.numpy() for k, v in predictions.items()}\n",
    "\n",
    "  @tf.function\n",
    "  def contribution_input_grad(self, input_sequence,\n",
    "                              target_mask, output_head='human'):\n",
    "    input_sequence = input_sequence[tf.newaxis]\n",
    "\n",
    "    target_mask_mass = tf.reduce_sum(target_mask)\n",
    "    with tf.GradientTape() as tape:\n",
    "      tape.watch(input_sequence)\n",
    "      prediction = tf.reduce_sum(\n",
    "          target_mask[tf.newaxis] *\n",
    "          self._model.predict_on_batch(input_sequence)[output_head]) / target_mask_mass\n",
    "\n",
    "    input_grad = tape.gradient(prediction, input_sequence) * input_sequence\n",
    "    input_grad = tf.squeeze(input_grad, axis=0)\n",
    "    return tf.reduce_sum(input_grad, axis=-1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsRaw:\n",
    "\n",
    "  def __init__(self, tfhub_url, organism='human'):\n",
    "    self._model = Enformer(tfhub_url)\n",
    "    self._organism = organism\n",
    "  \n",
    "  def predict_on_batch(self, inputs):\n",
    "    ref_prediction = self._model.predict_on_batch(inputs['ref'])[self._organism]\n",
    "    alt_prediction = self._model.predict_on_batch(inputs['alt'])[self._organism]\n",
    "\n",
    "    return alt_prediction.mean(axis=1) - ref_prediction.mean(axis=1)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsNormalized:\n",
    "\n",
    "  def __init__(self, tfhub_url, transform_pkl_path,\n",
    "               organism='human'):\n",
    "    assert organism == 'human', 'Transforms only compatible with organism=human'\n",
    "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "      transform_pipeline = joblib.load(f)\n",
    "    self._transform = transform_pipeline.steps[0][1]  # StandardScaler.\n",
    "    \n",
    "  def predict_on_batch(self, inputs):\n",
    "    scores = self._model.predict_on_batch(inputs)\n",
    "    return self._transform.transform(scores)\n",
    "\n",
    "\n",
    "class EnformerScoreVariantsPCANormalized:\n",
    "\n",
    "  def __init__(self, tfhub_url, transform_pkl_path,\n",
    "               organism='human', num_top_features=500):\n",
    "    self._model = EnformerScoreVariantsRaw(tfhub_url, organism)\n",
    "    with tf.io.gfile.GFile(transform_pkl_path, 'rb') as f:\n",
    "      self._transform = joblib.load(f)\n",
    "    self._num_top_features = num_top_features\n",
    "    \n",
    "  def predict_on_batch(self, inputs):\n",
    "    scores = self._model.predict_on_batch(inputs)\n",
    "    return self._transform.transform(scores)[:, :self._num_top_features]\n",
    "\n",
    "\n",
    "# TODO(avsec): Add feature description: Either PCX, or full names.\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "# @title `variant_centered_sequences`\n",
    "\n",
    "# @title `variant_centered_sequences`\n",
    "\n",
    "class FastaStringExtractor:\n",
    "    \n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "\n",
    "def variant_generator(vcf_file, gzipped=False,skip_lines = 0,max_lines = np.inf):\n",
    "  \"\"\"Yields a kipoiseq.dataclasses.Variant for each row in VCF file.\"\"\"\n",
    "  def _open(file):\n",
    "    return gzip.open(vcf_file, 'rt') if gzipped else open(vcf_file)\n",
    "    \n",
    "  with _open(vcf_file) as f:\n",
    "    for idx,line in enumerate(f):\n",
    "      if line.startswith('#') or line.startswith('CHROM'):\n",
    "        continue\n",
    "      \n",
    "      chrom, pos, id, ref, alt_list = line.split('\\t')[:5]\n",
    "\n",
    "        # Split ALT alleles and return individual variants as output.\n",
    "      for alt in alt_list.split(','):\n",
    "        yield kipoiseq.dataclasses.Variant(chrom=chrom, pos=pos,\n",
    "                                           ref=ref, alt=alt, id=id)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
    "\n",
    "\n",
    "def variant_centered_sequences(vcf_file, sequence_length, gzipped=False,\n",
    "                               chr_prefix=''):\n",
    "  seq_extractor = kipoiseq.extractors.VariantSeqExtractor(\n",
    "    reference_sequence=FastaStringExtractor(fasta_file))\n",
    "\n",
    "  for variant in variant_generator(vcf_file, gzipped=gzipped):\n",
    "    interval = Interval(chr_prefix + variant.chrom,\n",
    "                        variant.pos, variant.pos)\n",
    "    interval = interval.resize(sequence_length)\n",
    "    center = interval.center() - interval.start\n",
    "\n",
    "    reference = seq_extractor.extract(interval, [], anchor=center)\n",
    "    alternate = seq_extractor.extract(interval, [variant], anchor=center)\n",
    "\n",
    "    yield {'inputs': {'ref': one_hot_encode(reference),\n",
    "                      'alt': one_hot_encode(alternate)},\n",
    "           'metadata': {'chrom': chr_prefix + variant.chrom,\n",
    "                        'pos': variant.pos,\n",
    "                        'id': variant.id,\n",
    "                        'ref': variant.ref,\n",
    "                        'alt': variant.alt}}\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "model = Enformer(model_path)\n",
    "fasta_extractor = FastaStringExtractor(fasta_file)\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "\n",
    "#take variable number of MAF>0.05 1KG variants and get model(alt) - model(ref) predictions\n",
    "#take sum or max along sequence axis to get variant score for each track. Save these scores + variant position and allele metadata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e830caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_ALS = \"/wynton/home/hernandez/shirondru/pollard_lab/GWASPredictions/PsychENCODE_GWAS_Predictions/Sei/TEST/PsychENCODE_GWASVariants_TEST_SeiNoHeader.vcf00.vcf/PsychENCODE_GWASVariants_TEST_SeiNoHeader.vcf00.vcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a0f83ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACT\n",
      "AACTGTGT\n",
      "CTTT\n",
      "CTTT\n"
     ]
    }
   ],
   "source": [
    "# indel is an addition that adds 4 nt\n",
    "# and we correctly see that the addition of 4nt to the alt allele frameshifts the sequence to the right by 4nt\n",
    "#resulting in the GTGT missing from the end of the alt sequence, and only the 4 preceeding AACT appearing\n",
    "print(alt[-4:])\n",
    "print(ref[-8:])\n",
    "\n",
    "\n",
    "#however, the alt and ref seqs correctly have same sequence at the beginning, before the indel. \n",
    "print(alt[0:4])\n",
    "print(ref[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ca63af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_extractor = kipoiseq.extractors.VariantSeqExtractor(\n",
    "    reference_sequence=FastaStringExtractor(fasta_file))\n",
    "variant = kipoiseq.dataclasses.Variant(chrom='chr1', pos=84732076, ref='T', alt='TGGGC', id='')\n",
    "\n",
    "interval = Interval('' + variant.chrom,\n",
    "                        variant.pos, variant.pos)\n",
    "interval = interval.resize(seq_length)\n",
    "center = interval.center() - interval.start\n",
    "\n",
    "reference = seq_extractor.extract(interval, [], anchor=center)\n",
    "ref_N_composition = get_N_composition(reference)\n",
    "\n",
    "alternate = seq_extractor.extract(interval, [variant], anchor=center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af30cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTTTTTTTTTTTGAGACAGAGTCTCACTCTGTCACCCAGGCTGGAGTGCAGTGGCACGATCTTGGCTCACTGCAAGCTCCACCTCCCAGGTTCACACTATT\n",
      "TGGGCTTTTTTTTTTTGAGACAGAGTCTCACTCTGTCACCCAGGCTGGAGTGCAGTGGCACGATCTTGGCTCACTGCAAGCTCCACCTCCCAGGTTCACACTATT\n"
     ]
    }
   ],
   "source": [
    "window = len(reference)\n",
    "\n",
    "#first T nucleotide in ref seq is the reference allele\n",
    "#the TGGGC in the alternate seq is the alt allele. GGGC is the addition\n",
    "#printing the 100 nt to the right of the ref allele shows what exists after the indel in the ref seq\n",
    "#doing the same with the alt seq shows the frameshift is implemented correctly according to section 5 of:\n",
    "# http://samtools.github.io/hts-specs/VCFv4.2.pdf\n",
    "print(reference[(window//2)-1:(window//2)+100])\n",
    "print(alternate[(window//2)-1:(window//2)+104])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a85942ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACT\n",
      "AACTGTGT\n",
      "CTTT\n",
      "CTTT\n"
     ]
    }
   ],
   "source": [
    "# indel is an addition that adds 4 nt\n",
    "# and we correctly see that the addition of 4nt to the alt allele frameshifts the sequence to the right by 4nt\n",
    "#resulting in the GTGT missing from the end of the alt sequence, and only the 4 preceeding AACT appearing\n",
    "print(alternate[-4:])\n",
    "print(reference[-8:])\n",
    "\n",
    "\n",
    "#however, the alt and ref seqs correctly have same sequence at the beginning, before the indel. \n",
    "print(alternate[0:4])\n",
    "print(reference[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8a51a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524288"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reference[center:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412629f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pollard_environment",
   "language": "python",
   "name": "pollard_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
