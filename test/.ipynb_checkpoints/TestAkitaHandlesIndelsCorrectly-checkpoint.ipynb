{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee58e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sequence (InputLayer)           [(None, 1048576, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_reverse_complement ( ((None, 1048576, 4), 0           sequence[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stochastic_shift (StochasticShi (None, 1048576, 4)   0           stochastic_reverse_complement[0][\n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 1048576, 4)   0           stochastic_shift[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1048576, 96)  4224        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 1048576, 96)  384         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 524288, 96)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 524288, 96)   0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 524288, 96)   46080       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 524288, 96)   384         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 262144, 96)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 262144, 96)   0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 262144, 96)   46080       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 262144, 96)   384         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 131072, 96)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 131072, 96)   0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 131072, 96)   46080       re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 131072, 96)   384         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 65536, 96)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 65536, 96)    0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 65536, 96)    46080       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 65536, 96)    384         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 32768, 96)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 32768, 96)    0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 32768, 96)    46080       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32768, 96)    384         conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 16384, 96)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 16384, 96)    0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 16384, 96)    46080       re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16384, 96)    384         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 8192, 96)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 8192, 96)     0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8192, 96)     46080       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 8192, 96)     384         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 4096, 96)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 4096, 96)     0           max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 4096, 96)     46080       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 4096, 96)     384         conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 2048, 96)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 2048, 96)     0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2048, 96)     46080       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2048, 96)     384         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1024, 96)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 1024, 96)     0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1024, 96)     46080       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 1024, 96)     384         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 512, 96)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 512, 96)      0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 512, 48)      13824       re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 512, 48)      192         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 512, 48)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 512, 96)      4608        re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512, 96)      384         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512, 96)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 96)      0           max_pooling1d_10[0][0]           \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 512, 96)      0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 512, 48)      13824       re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 512, 48)      192         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 512, 48)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 512, 96)      4608        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 512, 96)      384         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512, 96)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 96)      0           add[0][0]                        \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 512, 96)      0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 512, 48)      13824       re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 512, 48)      192         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 512, 48)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 512, 96)      4608        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 96)      384         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512, 96)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 512, 96)      0           add_1[0][0]                      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 512, 96)      0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 512, 48)      13824       re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 48)      192         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 512, 48)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 512, 96)      4608        re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 96)      384         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512, 96)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 512, 96)      0           add_2[0][0]                      \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 512, 96)      0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 512, 48)      13824       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 48)      192         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 512, 48)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 512, 96)      4608        re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 512, 96)      384         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 512, 96)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 512, 96)      0           add_3[0][0]                      \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 512, 96)      0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 512, 48)      13824       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 512, 48)      192         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 512, 48)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 512, 96)      4608        re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 96)      384         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512, 96)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 512, 96)      0           add_4[0][0]                      \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 512, 96)      0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 512, 48)      13824       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 48)      192         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 512, 48)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 512, 96)      4608        re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512, 96)      384         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512, 96)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 512, 96)      0           add_5[0][0]                      \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 512, 96)      0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 512, 48)      13824       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 512, 48)      192         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 512, 48)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 512, 96)      4608        re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 512, 96)      384         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512, 96)      0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 96)      0           add_6[0][0]                      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 512, 96)      0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 512, 64)      30720       re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 512, 64)      256         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_28 (ReLU)                 (None, 512, 64)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "one_to_two (OneToTwo)           (None, 512, 512, 64) 0           re_lu_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_dist2d (ConcatDist2D)    (None, 512, 512, 65) 0           one_to_two[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_29 (ReLU)                 (None, 512, 512, 65) 0           concat_dist2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 48) 28080       re_lu_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 512, 512, 48) 192         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d (Symmetrize2D)     (None, 512, 512, 48) 0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_30 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 512, 512, 24) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_31 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 48) 1152        re_lu_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512, 512, 48) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512, 512, 48) 0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 512, 48) 0           symmetrize2d[0][0]               \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_1 (Symmetrize2D)   (None, 512, 512, 48) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_32 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 512, 512, 24) 96          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_33 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 512, 512, 48) 1152        re_lu_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 512, 512, 48) 192         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512, 512, 48) 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 512, 512, 48) 0           symmetrize2d_1[0][0]             \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_2 (Symmetrize2D)   (None, 512, 512, 48) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_34 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 512, 512, 24) 96          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_35 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 512, 48) 1152        re_lu_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 512, 512, 48) 192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 512, 512, 48) 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_2[0][0]             \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_3 (Symmetrize2D)   (None, 512, 512, 48) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_36 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 512, 512, 24) 96          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_37 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 512, 512, 48) 1152        re_lu_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 512, 512, 48) 192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512, 512, 48) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_3[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_4 (Symmetrize2D)   (None, 512, 512, 48) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 512, 512, 24) 10368       re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 512, 512, 24) 96          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 512, 512, 48) 1152        re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 512, 512, 48) 192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 512, 512, 48) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_4[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_5 (Symmetrize2D)   (None, 512, 512, 48) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 512, 512, 48) 0           symmetrize2d_5[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 512, 512, 24) 10368       re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 512, 512, 24) 96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_41 (ReLU)                 (None, 512, 512, 24) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 512, 512, 48) 1152        re_lu_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 512, 512, 48) 192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 512, 512, 48) 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 512, 512, 48) 0           symmetrize2d_5[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "symmetrize2d_6 (Symmetrize2D)   (None, 512, 512, 48) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d (Cropping2D)         (None, 448, 448, 48) 0           symmetrize2d_6[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "upper_tri (UpperTri)            (None, 99681, 48)    0           cropping2d[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 99681, 5)     245         upper_tri[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "switch_reverse_triu (SwitchReve (None, 99681, 5)     0           dense[0][0]                      \n",
      "                                                                 stochastic_reverse_complement[0][\n",
      "==================================================================================================\n",
      "Total params: 751,653\n",
      "Trainable params: 746,149\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "model_strides [2048]\n",
      "target_lengths [99681]\n",
      "target_crops [-49585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import shutil\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1' ### run on CPU\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "if tf.__version__[0] == '1':\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import matplotlib.pyplot as plt\n",
    "from cooltools.lib.numutils import set_diag\n",
    "import sys\n",
    "sys.path.append(\"/wynton/home/hernandez/shirondru/pollard_lab/basenji\")\n",
    "from basenji import dataset, dna_io, seqnn\n",
    "\n",
    "import cooler\n",
    "import cooltools\n",
    "from cooltools.lib.numutils import observed_over_expected\n",
    "from cooltools.lib.numutils import adaptive_coarsegrain\n",
    "from cooltools.lib.numutils import interpolate_bad_singletons\n",
    "from cooltools.lib.numutils import interp_nan, set_diag\n",
    "from cooltools.lib.plotting import *\n",
    "\n",
    "\n",
    "import kipoiseq\n",
    "from kipoiseq import Interval\n",
    "import pyfaidx\n",
    "\n",
    "from collections import Counter\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "### load params, specify model ###\n",
    "\n",
    "model_dir = '/wynton/home/hernandez/shirondru/pollard_lab/'\n",
    "params_file = model_dir+'params.json'\n",
    "model_file  = model_dir+'model_best.h5'\n",
    "with open(params_file) as params_open:\n",
    "    params = json.load(params_open)\n",
    "    params_model = params['model']\n",
    "    params_train = params['train']\n",
    "\n",
    "seqnn_model = seqnn.SeqNN(params_model)\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "### restore model ###\n",
    "# note: run %%bash get_model.sh \n",
    "# if you have not already downloaded the model\n",
    "seqnn_model.restore(model_file)\n",
    "print('successfully loaded')\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "### names of targets ###\n",
    "data_dir =  os.path.join(model_dir,\"basenji/manuscripts/akita/data/\")\n",
    "\n",
    "hic_targets = pd.read_csv(data_dir+'/targets.txt',sep='\\t')\n",
    "hic_file_dict_num = dict(zip(hic_targets['index'].values, hic_targets['file'].values) )\n",
    "hic_file_dict     = dict(zip(hic_targets['identifier'].values, hic_targets['file'].values) )\n",
    "hic_num_to_name_dict = dict(zip(hic_targets['index'].values, hic_targets['identifier'].values) )\n",
    "\n",
    "# read data parameters\n",
    "data_stats_file = '%s/statistics.json' % data_dir\n",
    "with open(data_stats_file) as data_stats_open:\n",
    "    data_stats = json.load(data_stats_open)\n",
    "seq_length = data_stats['seq_length']\n",
    "target_length = data_stats['target_length']\n",
    "hic_diags =  data_stats['diagonal_offset']\n",
    "target_crop = data_stats['crop_bp'] // data_stats['pool_width']\n",
    "target_length1 = data_stats['seq_length'] // data_stats['pool_width']\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "fasta_file = '/wynton/home/hernandez/shirondru/pollard_lab/data/hg38_genome.fa'\n",
    "\n",
    "\n",
    "### for converting from flattened upper-triangluar vector to symmetric matrix  ###\n",
    "\n",
    "def from_upper_triu(vector_repr, matrix_len, num_diags):\n",
    "    z = np.zeros((matrix_len,matrix_len))\n",
    "    triu_tup = np.triu_indices(matrix_len,num_diags)\n",
    "    z[triu_tup] = vector_repr\n",
    "    for i in range(-num_diags+1,num_diags):\n",
    "        set_diag(z, np.nan, i)\n",
    "    return z + z.T\n",
    "\n",
    "\n",
    "def preprocess_from_cool(myseq_str, genome_hic_cool):\n",
    "    print(\"Seq-str: \", myseq_str)\n",
    "    num_counts= np.sum(genome_hic_cool.matrix(balance=False).fetch(myseq_str))\n",
    "    seq_hic_obs = genome_hic_cool.matrix(balance=True).fetch(myseq_str)\n",
    "    seq_hic_smoothed =  adaptive_coarsegrain(\n",
    "                     seq_hic_obs,  \n",
    "                     genome_hic_cool.matrix(balance=False).fetch(myseq_str),  \n",
    "                     cutoff=3, max_levels=8)\n",
    "    seq_hic_nan = np.isnan(seq_hic_smoothed)\n",
    "    seq_hic_obsexp = observed_over_expected(seq_hic_smoothed, ~seq_hic_nan)[0]\n",
    "    seq_hic_obsexp = np.log(seq_hic_obsexp)\n",
    "    seq_hic_obsexp = np.clip(seq_hic_obsexp,-2,2)\n",
    "    seq_hic_obsexp_init = np.copy(seq_hic_obsexp)\n",
    "    seq_hic_obsexp = interp_nan(seq_hic_obsexp)\n",
    "    seq_hic_obsexp = np.nan_to_num(seq_hic_obsexp)\n",
    "    seq_hic = np.clip(seq_hic_obsexp,-2,2)\n",
    "    for i in [-1,0,1]: set_diag(seq_hic, 0,i)\n",
    "        \n",
    "    from astropy.convolution import Gaussian2DKernel\n",
    "    from astropy.convolution import convolve\n",
    "    kernel = Gaussian2DKernel(x_stddev=1,x_size=5)\n",
    "\n",
    "    seq_hic = convolve(seq_hic, kernel)\n",
    "    return seq_hic, num_counts, seq_hic_obs\n",
    "\n",
    "\n",
    "def get_expt(region_chr, region_start, region_stop):\n",
    "    myseq_str = \"{}:{}-{}\".format(region_chr, region_start, region_stop)\n",
    "    expt, num_counts, expt_obs = preprocess_from_cool(myseq_str, genome_hic_cool)\n",
    "    new_start = int((target_length - target_length_cropped)/2)\n",
    "    new_end = int(target_length-new_start)\n",
    "    expt = expt[new_start:target_length-new_start, new_start:target_length-new_start]\n",
    "    return(expt)\n",
    "\n",
    "\n",
    "# @title `variant_centered_sequences`\n",
    "\n",
    "class FastaStringExtractor:\n",
    "    \n",
    "    def __init__(self, fasta_file):\n",
    "        self.fasta = pyfaidx.Fasta(fasta_file)\n",
    "        self._chromosome_sizes = {k: len(v) for k, v in self.fasta.items()}\n",
    "\n",
    "    def extract(self, interval: Interval, **kwargs) -> str:\n",
    "        # Truncate interval if it extends beyond the chromosome lengths.\n",
    "        chromosome_length = self._chromosome_sizes[interval.chrom]\n",
    "        trimmed_interval = Interval(interval.chrom,\n",
    "                                    max(interval.start, 0),\n",
    "                                    min(interval.end, chromosome_length),\n",
    "                                    )\n",
    "        # pyfaidx wants a 1-based interval\n",
    "        sequence = str(self.fasta.get_seq(trimmed_interval.chrom,\n",
    "                                          trimmed_interval.start + 1,\n",
    "                                          trimmed_interval.stop).seq).upper()\n",
    "        # Fill truncated values with N's.\n",
    "        pad_upstream = 'N' * max(-interval.start, 0)\n",
    "        pad_downstream = 'N' * max(interval.end - chromosome_length, 0)\n",
    "        return pad_upstream + sequence + pad_downstream\n",
    "\n",
    "    def close(self):\n",
    "        return self.fasta.close()\n",
    "\n",
    "\n",
    "def variant_generator(vcf_file, gzipped=False):\n",
    "  \"\"\"Yields a kipoiseq.dataclasses.Variant for each row in VCF file.\"\"\"\n",
    "  def _open(file):\n",
    "    return gzip.open(vcf_file, 'rt') if gzipped else open(vcf_file)\n",
    "    \n",
    "  with _open(vcf_file) as f:\n",
    "    for line in f:\n",
    "      if line.startswith('#') or line.startswith('CHROM'):\n",
    "        continue\n",
    "      chrom, pos, id, ref, alt_list = line.split('\\t')[:5]\n",
    "      # Split ALT alleles and return individual variants as output.\n",
    "      for alt in alt_list.split(','):\n",
    "        yield kipoiseq.dataclasses.Variant(chrom=chrom, pos=pos,\n",
    "                                           ref=ref, alt=alt, id=id)\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence):\n",
    "  return kipoiseq.transforms.functional.one_hot_dna(sequence).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_N_composition(seq: str):\n",
    "    \"\"\"\n",
    "    Get % of N's in input sequence\n",
    "    \n",
    "    Input: \n",
    "        seq: string of sequence\n",
    "    Returns: % of Ns in input sequence\n",
    "    \"\"\"\n",
    "    count = Counter(seq)\n",
    "    \n",
    "    for key, value in count.items():\n",
    "        count[key] = round(value/len(seq)*100,2)\n",
    "#     if 'N' in count.keys():\n",
    "    if count['N'] > 0:\n",
    "        return count['N']\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "def variant_centered_sequences(vcf_file, sequence_length, gzipped=False,\n",
    "                               chr_prefix=''):\n",
    "  seq_extractor = kipoiseq.extractors.VariantSeqExtractor(\n",
    "    reference_sequence=FastaStringExtractor(fasta_file))\n",
    "\n",
    "  for variant in variant_generator(vcf_file, gzipped=gzipped):\n",
    "    interval = Interval(chr_prefix + variant.chrom,\n",
    "                        variant.pos, variant.pos)\n",
    "    interval = interval.resize(sequence_length)\n",
    "    center = interval.center() - interval.start\n",
    "\n",
    "    reference = seq_extractor.extract(interval, [], anchor=center)\n",
    "    ref_N_composition = get_N_composition(reference)\n",
    "    \n",
    "    alternate = seq_extractor.extract(interval, [variant], anchor=center)\n",
    "    alt_N_composition = get_N_composition(alternate)\n",
    "    yield {'inputs': {'ref': reference,\n",
    "                      'alt': alternate},\n",
    "           'metadata': {'chrom': chr_prefix + variant.chrom,\n",
    "                        'pos': variant.pos,\n",
    "                        'id': variant.id,\n",
    "                        'ref': variant.ref,\n",
    "                        'alt': variant.alt,\n",
    "                        'ref_N_composition':ref_N_composition,\n",
    "                        'alt_N_composition':alt_N_composition}}\n",
    "    \n",
    "    \n",
    "def msd(alternate_prediction, reference_prediction):\n",
    "    \n",
    "    #returns Mean squared difference between alt and ref predictions for each cell line\n",
    "    return np.nanmean(np.square(alternate_prediction - reference_prediction),axis = 1).reshape(-1)\n",
    "\n",
    "def max_diff(alternate_prediction, reference_prediction):\n",
    "    #returns max difference between absolute value of alt and ref predictions for each cell line\n",
    "\n",
    "\n",
    "    return np.max(abs(alternate_prediction - reference_prediction),axis = 1).reshape(-1)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e830caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_ALS = \"/wynton/home/hernandez/shirondru/pollard_lab/GWASPredictions/PsychENCODE_GWAS_Predictions/Sei/TEST/PsychENCODE_GWASVariants_TEST_SeiNoHeader.vcf00.vcf/PsychENCODE_GWASVariants_TEST_SeiNoHeader.vcf00.vcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614385b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_extractor = kipoiseq.extractors.VariantSeqExtractor(\n",
    "    reference_sequence=FastaStringExtractor(fasta_file))\n",
    "variant = kipoiseq.dataclasses.Variant(chrom='chr1', pos=84732076, ref='T', alt='TGGGC', id='')\n",
    "\n",
    "interval = Interval('' + variant.chrom,\n",
    "                        variant.pos, variant.pos)\n",
    "interval = interval.resize(seq_length)\n",
    "center = interval.center() - interval.start\n",
    "\n",
    "reference = seq_extractor.extract(interval, [], anchor=center)\n",
    "ref_N_composition = get_N_composition(reference)\n",
    "\n",
    "alternate = seq_extractor.extract(interval, [variant], anchor=center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a0f83ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACT\n",
      "AACTGTGT\n",
      "CTTT\n",
      "CTTT\n"
     ]
    }
   ],
   "source": [
    "# indel is an addition that adds 4 nt\n",
    "# and we correctly see that the addition of 4nt to the alt allele frameshifts the sequence to the right by 4nt\n",
    "#resulting in the GTGT missing from the end of the alt sequence, and only the 4 preceeding AACT appearing\n",
    "print(alt[-4:])\n",
    "print(ref[-8:])\n",
    "\n",
    "\n",
    "#however, the alt and ref seqs correctly have same sequence at the beginning, before the indel. \n",
    "print(alt[0:4])\n",
    "print(ref[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ca63af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_extractor = kipoiseq.extractors.VariantSeqExtractor(\n",
    "    reference_sequence=FastaStringExtractor(fasta_file))\n",
    "variant = kipoiseq.dataclasses.Variant(chrom='chr1', pos=84732076, ref='T', alt='TGGGC', id='')\n",
    "\n",
    "interval = Interval('' + variant.chrom,\n",
    "                        variant.pos, variant.pos)\n",
    "interval = interval.resize(seq_length)\n",
    "center = interval.center() - interval.start\n",
    "\n",
    "reference = seq_extractor.extract(interval, [], anchor=center)\n",
    "ref_N_composition = get_N_composition(reference)\n",
    "\n",
    "alternate = seq_extractor.extract(interval, [variant], anchor=center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af30cfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTTTTTTTTTTTGAGACAGAGTCTCACTCTGTCACCCAGGCTGGAGTGCAGTGGCACGATCTTGGCTCACTGCAAGCTCCACCTCCCAGGTTCACACTATT\n",
      "TGGGCTTTTTTTTTTTGAGACAGAGTCTCACTCTGTCACCCAGGCTGGAGTGCAGTGGCACGATCTTGGCTCACTGCAAGCTCCACCTCCCAGGTTCACACTATT\n"
     ]
    }
   ],
   "source": [
    "window = len(reference)\n",
    "\n",
    "#first T nucleotide in ref seq is the reference allele\n",
    "#the TGGGC in the alternate seq is the alt allele. GGGC is the addition\n",
    "#printing the 100 nt to the right of the ref allele shows what exists after the indel in the ref seq\n",
    "#doing the same with the alt seq shows the frameshift is implemented correctly according to section 5 of:\n",
    "# http://samtools.github.io/hts-specs/VCFv4.2.pdf\n",
    "print(reference[(window//2)-1:(window//2)+100])\n",
    "print(alternate[(window//2)-1:(window//2)+104])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a85942ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AACT\n",
      "AACTGTGT\n",
      "CTTT\n",
      "CTTT\n"
     ]
    }
   ],
   "source": [
    "# indel is an addition that adds 4 nt\n",
    "# and we correctly see that the addition of 4nt to the alt allele frameshifts the sequence to the right by 4nt\n",
    "#resulting in the GTGT missing from the end of the alt sequence, and only the 4 preceeding AACT appearing\n",
    "print(alternate[-4:])\n",
    "print(reference[-8:])\n",
    "\n",
    "\n",
    "#however, the alt and ref seqs correctly have same sequence at the beginning, before the indel. \n",
    "print(alternate[0:4])\n",
    "print(reference[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8a51a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524288"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reference[center:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c412629f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pollard_environment",
   "language": "python",
   "name": "pollard_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
